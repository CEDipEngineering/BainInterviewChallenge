{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a better Machine Learning Model\n",
    "\n",
    "I was very unsatisfied with the supplied model, and so decided to make my own. I know, this was outside the given task, but I finished early, and wanted to see if I could do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model.data import load_data\n",
    "\n",
    "def print_metrics(predictions, target):\n",
    "    print(\"RMSE: \", np.sqrt(mean_squared_error(predictions, target)))\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(predictions, target))\n",
    "    print(\"MAE : \", mean_absolute_error(predictions, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and separate data into train, validation, and test. Test data will only be used at the end, once I've decided not to tweak the models any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12969, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = load_data()\n",
    "X_train_full, Y_train_full, X_test, Y_test = train.drop(\"price\", axis=1), train[\"price\"], test.drop(\"price\", axis=1), test[\"price\"]\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_full, Y_train_full, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick run-down of the available features and some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3950</th>\n",
       "      <th>2286</th>\n",
       "      <th>10662</th>\n",
       "      <th>714</th>\n",
       "      <th>10474</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>departamento</td>\n",
       "      <td>casa</td>\n",
       "      <td>casa</td>\n",
       "      <td>departamento</td>\n",
       "      <td>departamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <td>providencia</td>\n",
       "      <td>lo barnechea</td>\n",
       "      <td>las condes</td>\n",
       "      <td>nunoa</td>\n",
       "      <td>providencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_usable_area</th>\n",
       "      <td>91.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_area</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_rooms</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_bathroom</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-33.4376</td>\n",
       "      <td>-33.33118</td>\n",
       "      <td>-33.42117</td>\n",
       "      <td>-33.4531</td>\n",
       "      <td>-33.42707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-70.627</td>\n",
       "      <td>-70.52862</td>\n",
       "      <td>-70.50105</td>\n",
       "      <td>-70.602</td>\n",
       "      <td>-70.6114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        3950          2286        10662         714    \\\n",
       "type             departamento          casa        casa  departamento   \n",
       "sector            providencia  lo barnechea  las condes         nunoa   \n",
       "net_usable_area          91.0         577.0       365.0          40.0   \n",
       "net_area                 97.0        1276.0       980.0          43.0   \n",
       "n_rooms                   3.0           7.0         7.0           1.0   \n",
       "n_bathroom                2.0           6.0         4.0           1.0   \n",
       "latitude             -33.4376     -33.33118   -33.42117      -33.4531   \n",
       "longitude             -70.627     -70.52862   -70.50105       -70.602   \n",
       "\n",
       "                        10474  \n",
       "type             departamento  \n",
       "sector            providencia  \n",
       "net_usable_area          60.0  \n",
       "net_area                 60.0  \n",
       "n_rooms                   2.0  \n",
       "n_bathroom                1.0  \n",
       "latitude            -33.42707  \n",
       "longitude            -70.6114  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen the features, I have decided to apply some feature engineering, aside from the OneHotEncoding that was already used in the original model.\n",
    "\n",
    "1. Tweak the latitude and longitude, since all properties are somewhat close-by. My suggestion is standard normalization using mean and standard deviation.\n",
    "\n",
    "2. A couple of new features: \n",
    "    - pct_usable_area: Dividing the net_usable_area by the total net_area, gives a percentage of usable area.\n",
    "    - avg_area_per_room: Dividing the net_usable_area by the n_rooms, to give a sense for how big the rooms are.\n",
    "\n",
    "3. Drop the transformed columns so there is no data co-dependecy and repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9435156932680938, -1.8282648093401392, 0.0, ..., 2.0,\n",
       "        30.333333333333332, 0.9381443298969072],\n",
       "       [2.007267618074679, 0.8919459513170356, 1.0, ..., 6.0,\n",
       "        82.42857142857143, 0.45219435736677116],\n",
       "       [-0.48794935418370217, 1.654257505202155, 1.0, ..., 4.0,\n",
       "        52.142857142857146, 0.37244897959183676],\n",
       "       ...,\n",
       "       [-0.5966419926019136, 0.3441986940620855, 1.0, ..., 1.0,\n",
       "        36.666666666666664, 0.43824701195219123],\n",
       "       [-0.8755827942566378, 1.0290901409170414, 1.0, ..., 1.0, 20.0,\n",
       "        0.18461538461538463],\n",
       "       [-0.33073321647162157, -0.031012324661606826, 0.0, ..., 2.0, 33.0,\n",
       "        0.9428571428571428]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@FunctionTransformer\n",
    "def feature_expansion(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    input_df[\"avg_area_per_room\"] = input_df[\"net_usable_area\"].div(input_df[\"n_rooms\"], fill_value=0.0)\n",
    "    input_df[\"pct_usable_area\"] = input_df[\"net_usable_area\"].div(input_df[\"net_area\"], fill_value=0.0)\n",
    "    return input_df.fillna(0.0).replace(np.inf, 0.0)\n",
    "\n",
    "class columnDropperTransformer(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        all_cols = np.ones(X.shape[-1]).astype(bool)\n",
    "        all_cols[self.columns] = False\n",
    "        return X[:, all_cols]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "column_name_index = {k: v for v,k in enumerate(train.columns.to_list())}\n",
    "\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"Feature Transformations and Scaling\", \n",
    "         ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('Standard Scaler for Lat/Long', StandardScaler(), [column_name_index[\"latitude\"], column_name_index[\"longitude\"]]),\n",
    "                ('One Hot Encoder for Type/Sector', OneHotEncoder(handle_unknown='ignore'), [column_name_index['type'], column_name_index['sector']]),\n",
    "                ('Additional Feature Engineering', feature_expansion, make_column_selector('.*')),\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )),\n",
    "        (\"Drop transformed features\", \n",
    "         columnDropperTransformer([11, 10, 16, 17])) # Drop type, sector, lat, long\n",
    "    ]\n",
    ")\n",
    "preprocessing_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the preprocessing is done, I have to decide which model to use. For this, I picked some examples from the sklearn documentation, and my personal favorite, RandomForestRegressor. I skipped XGBoost, or other gradient-boosted trees, because they often perform very similarly to RFR, and it seemed like it would be a waste of effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_regressor = LinearRegression()\n",
    "lr_pipeline = Pipeline([\n",
    "    ('Preprocessing', preprocessing_pipeline),\n",
    "    ('Regression', lr_regressor)\n",
    "])\n",
    "\n",
    "encv_regressor = ElasticNetCV()\n",
    "encv_params = {\n",
    "    \"max_iter\": [3000, 5000, 10000],\n",
    "    \"l1_ratio\": list(np.linspace(0.05, 0.95, 10)),\n",
    "    \"selection\": ['random', 'cyclic']\n",
    "}\n",
    "\n",
    "rfr_regressor = RandomForestRegressor()\n",
    "rfr_pipeline = Pipeline([\n",
    "    ('Preprocessing', preprocessing_pipeline),\n",
    "    ('Regression', rfr_regressor)\n",
    "])\n",
    "rfr_params = {\n",
    "    \"n_estimators\": [100, 300, 500, 700],\n",
    "    \"criterion\": [\"squared_error\", \"friedman_mse\"],\n",
    "    \"max_depth\": [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then trained each model using GridSearchCV to check for the best parameters. Linear Regression did not need GridSearch or CV, since it has no parameters and is completely deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_valid = preprocessing_pipeline.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  9637.299292253598\n",
      "MAPE:  0.4827414601975945\n",
      "MAE :  5524.312616903214\n"
     ]
    }
   ],
   "source": [
    "best_lr = lr_regressor.fit(X_train, Y_train)\n",
    "preds = best_lr.predict(X_valid)\n",
    "print_metrics(preds, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  13301.431569229171\n",
      "MAPE:  0.5509217631167143\n",
      "MAE :  8895.797455962736\n"
     ]
    }
   ],
   "source": [
    "encv_grid = GridSearchCV(encv_regressor, encv_params)\n",
    "encv_grid.fit(X_train, Y_train)\n",
    "best_encv = encv_grid.best_estimator_\n",
    "preds = best_encv.predict(X_valid)\n",
    "print_metrics(preds, Y_valid)\n",
    "\n",
    "# encv_pipeline = Pipeline([\n",
    "#     ('Preprocessing', preprocessing_pipeline),\n",
    "#     ('Regression', encv_regressor)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4635.834611122243\n",
      "MAPE:  0.12092692450043732\n",
      "MAE :  2171.1305229281716\n"
     ]
    }
   ],
   "source": [
    "rfr_grid = GridSearchCV(rfr_regressor, rfr_params, n_jobs=-1, cv=3)\n",
    "rfr_grid.fit(X_train, Y_train)\n",
    "best_rfr = rfr_grid.best_estimator_\n",
    "preds = best_rfr.predict(X_valid)\n",
    "print_metrics(preds, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained all three, RFR did the best (including better than the original model) by a very large margin. Having settled on this model, I then assembled the final pipeline and applied it to the as-of-yet untouched test data to get a sense for real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest Regressor {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'max_depth': 100, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;Feature Transformations and Scaling&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;Standard &#x27;\n",
       "                                                                   &#x27;Scaler for &#x27;\n",
       "                                                                   &#x27;Lat/Long&#x27;,\n",
       "                                                                   StandardScaler(),\n",
       "                                                                   [6, 7]),\n",
       "                                                                  (&#x27;One Hot &#x27;\n",
       "                                                                   &#x27;Encoder &#x27;\n",
       "                                                                   &#x27;for &#x27;\n",
       "                                                                   &#x27;Type/Sector&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                   [0, 1]),\n",
       "                                                                  (&#x27;Additional &#x27;\n",
       "                                                                   &#x27;Feature &#x27;\n",
       "                                                                   &#x27;Engineering&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function feature_expansion at 0x7f35bc67fb80&gt;),\n",
       "                                                                   &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670&gt;)])),\n",
       "                                 (&#x27;Drop transformed features&#x27;,\n",
       "                                  &lt;__main__.columnDropperTransformer object at 0x7f356b6e2880&gt;)])),\n",
       "                (&#x27;Regressor&#x27;,\n",
       "                 RandomForestRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                       max_depth=100))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;Feature Transformations and Scaling&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;Standard &#x27;\n",
       "                                                                   &#x27;Scaler for &#x27;\n",
       "                                                                   &#x27;Lat/Long&#x27;,\n",
       "                                                                   StandardScaler(),\n",
       "                                                                   [6, 7]),\n",
       "                                                                  (&#x27;One Hot &#x27;\n",
       "                                                                   &#x27;Encoder &#x27;\n",
       "                                                                   &#x27;for &#x27;\n",
       "                                                                   &#x27;Type/Sector&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                   [0, 1]),\n",
       "                                                                  (&#x27;Additional &#x27;\n",
       "                                                                   &#x27;Feature &#x27;\n",
       "                                                                   &#x27;Engineering&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function feature_expansion at 0x7f35bc67fb80&gt;),\n",
       "                                                                   &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670&gt;)])),\n",
       "                                 (&#x27;Drop transformed features&#x27;,\n",
       "                                  &lt;__main__.columnDropperTransformer object at 0x7f356b6e2880&gt;)])),\n",
       "                (&#x27;Regressor&#x27;,\n",
       "                 RandomForestRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                       max_depth=100))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Feature Transformations and Scaling&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;Standard Scaler for &#x27;\n",
       "                                                  &#x27;Lat/Long&#x27;,\n",
       "                                                  StandardScaler(), [6, 7]),\n",
       "                                                 (&#x27;One Hot Encoder for &#x27;\n",
       "                                                  &#x27;Type/Sector&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [0, 1]),\n",
       "                                                 (&#x27;Additional Feature &#x27;\n",
       "                                                  &#x27;Engineering&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function feature_expansion at 0x7f35bc67fb80&gt;),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670&gt;)])),\n",
       "                (&#x27;Drop transformed features&#x27;,\n",
       "                 &lt;__main__.columnDropperTransformer object at 0x7f356b6e2880&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Feature Transformations and Scaling: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;Standard Scaler for Lat/Long&#x27;,\n",
       "                                 StandardScaler(), [6, 7]),\n",
       "                                (&#x27;One Hot Encoder for Type/Sector&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [0, 1]),\n",
       "                                (&#x27;Additional Feature Engineering&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function feature_expansion at 0x7f35bc67fb80&gt;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Standard Scaler for Lat/Long</label><div class=\"sk-toggleable__content\"><pre>[6, 7]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">One Hot Encoder for Type/Sector</label><div class=\"sk-toggleable__content\"><pre>[0, 1]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Additional Feature Engineering</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function feature_expansion at 0x7f35bc67fb80&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columnDropperTransformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.columnDropperTransformer object at 0x7f356b6e2880&gt;</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=100)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Preprocessing',\n",
       "                 Pipeline(steps=[('Feature Transformations and Scaling',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('Standard '\n",
       "                                                                   'Scaler for '\n",
       "                                                                   'Lat/Long',\n",
       "                                                                   StandardScaler(),\n",
       "                                                                   [6, 7]),\n",
       "                                                                  ('One Hot '\n",
       "                                                                   'Encoder '\n",
       "                                                                   'for '\n",
       "                                                                   'Type/Sector',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                   [0, 1]),\n",
       "                                                                  ('Additional '\n",
       "                                                                   'Feature '\n",
       "                                                                   'Engineering',\n",
       "                                                                   FunctionTransformer(func=<function feature_expansion at 0x7f35bc67fb80>),\n",
       "                                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f356b6e2670>)])),\n",
       "                                 ('Drop transformed features',\n",
       "                                  <__main__.columnDropperTransformer object at 0x7f356b6e2880>)])),\n",
       "                ('Regressor',\n",
       "                 RandomForestRegressor(criterion='friedman_mse',\n",
       "                                       max_depth=100))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best parameters for Random Forest Regressor\", best_rfr.get_params())\n",
    "best_model = Pipeline(\n",
    "    [   \n",
    "        (\"Preprocessing\", preprocessing_pipeline),\n",
    "        (\"Regressor\", best_rfr),\n",
    "    ]\n",
    ")\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4419.856688043476\n",
      "MAPE:  0.12061920163764589\n",
      "MAE :  2136.564544270231\n"
     ]
    }
   ],
   "source": [
    "final_prediction = best_model.predict(X_test)\n",
    "print_metrics(final_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again, very good performance. I decided not to replace this model with the original in the API, since it is outside the scope of the project, but it would be very easy. Just a few tweaks to the model.py class, and maybe change the BaseModel for the API in case the inputs don't match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RE_Chile_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
